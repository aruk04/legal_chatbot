from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, ConfigDict
import uvicorn
from sqlmodel import Field, SQLModel, Relationship, create_engine, Session
from sqlalchemy.orm import selectinload
import os

from retriever import load_artifacts, retrieve_sections
from rule_engine import determine_forum, check_eligibility
from llm_agent import initialize_summarizer, generate_layman_summary
import joblib
from complaint_analyzer import ComplaintAnalyzer
import json
# New import for the intent prediction logic
from intent_predictor import load_predictor_models, predict_intent_with_fallback

# Initialize FastAPI app
app = FastAPI()

# Add CORS middleware to allow requests from your React frontend
# Adjust `allow_origins` in production to your frontend's domain
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # React frontend runs on port 3000 by default
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global variables to store loaded artifacts and model
index = None
sections_data = None
model = None

# Global variable for ComplaintAnalyzer
complaint_analyzer = None

# Pydantic model for incoming chat requests
class ChatRequest(BaseModel):
    user_query: str
    session_id_uuid: str | None = None  # New: To link messages to a specific session
    price: str | None = None
    date: str | None = None

# Pydantic model for incoming complaint analysis requests
class ComplaintAnalysisRequest(BaseModel):
    complaint_text: str

class AddComplaintRequest(BaseModel):
    complaint_text: str
    intent_label: str

# Make sure to import datetime and Column from sqlalchemy for JSON type
from datetime import datetime
from sqlalchemy import Column
from sqlalchemy.dialects.mysql import JSON

# Database setup for SQLModel
# Using os.getenv to keep sensitive info out of code, with a fallback for local dev
DATABASE_URL = os.getenv("DATABASE_URL", "mysql+pymysql://root:@localhost:3306/legal_qa_chatbot_db")

engine = create_engine(DATABASE_URL, echo=True)

def create_db_and_tables():
    print("Creating database tables...")
    SQLModel.metadata.create_all(engine)
    print("✅ Database tables created (or already exist).")

# SQLModel classes for chat history
class ChatSession(SQLModel, table=True):
    model_config = ConfigDict(arbitrary_types_allowed=True) # Add this line
    id: int | None = Field(default=None, primary_key=True)
    session_id_uuid: str = Field(index=True, unique=True)
    title: str
    created_at: datetime = Field(default_factory=datetime.now)
    updated_at: datetime = Field(default_factory=datetime.now)

    messages: list["Message"] = Relationship(back_populates="session")

class Message(SQLModel, table=True):
    model_config = ConfigDict(arbitrary_types_allowed=True) # Add this line
    id: int | None = Field(default=None, primary_key=True)
    session_id: int = Field(foreign_key="chatsession.id")
    sender: str
    text_content: str
    price: str | None = None
    date: str | None = None
    response_data: str | None = Field(default=None, sa_column=Column(JSON))
    timestamp: datetime = Field(default_factory=datetime.now)

    session: ChatSession = Relationship(back_populates="messages")

    # Required for JSON column (if you decide to use it, otherwise remove)
    __table_args__ = {"mysql_charset": "utf8mb4"}

# New Pydantic/SQLModel classes for database interaction (defined AFTER ChatSession and Message)

# For reading messages (explicitly defined to avoid SQLAlchemy relationship mapping issues in Pydantic)
class MessageRead(SQLModel):
    id: int
    sender: str
    text_content: str
    price: str | None = None
    date: str | None = None
    response_data: str | None = None # This will be the JSON string, not a complex object
    timestamp: datetime

# For reading chat sessions (explicitly defined, including related MessageRead objects)
class ChatSessionRead(SQLModel):
    id: int
    session_id_uuid: str
    title: str
    created_at: datetime
    updated_at: datetime
    messages: list[MessageRead] = [] # Include messages as a list of MessageRead objects

# For creating new chat sessions (frontend will send this)
class ChatSessionCreate(BaseModel):
    session_id_uuid: str
    title: str

# For creating new messages (frontend will send this, or backend will create for bot)
class MessageCreate(BaseModel):
    session_id_uuid: str # Use UUID for frontend communication
    sender: str
    text_content: str
    price: str | None = None
    date: str | None = None
    # response_data is generated by backend, not sent by frontend for creation

# Dependency to get a database session
def get_session():
    with Session(engine) as session:
        yield session

@app.on_event("startup")
def startup_event():
    global index, sections_data, model, complaint_analyzer
    print("Application startup: Loading artifacts and initializing LLM summarizer...")
    try:
        create_db_and_tables() # Create tables on startup

        # Initialize LLM summarizer first (downloads model if not present)
        initialize_summarizer()
        
        # Load FAISS index and sections data
        faiss_index_path = "cpa_faiss_index.bin"
        sections_map_path = "sections_map.json"
        index, sections_data, model = load_artifacts(faiss_index_path, sections_map_path)
        print("✅ Backend artifacts loaded.")

        # Initialize and load ComplaintAnalyzer models for retraining/admin purposes
        complaint_analyzer = ComplaintAnalyzer()
        # We don't need to load classifier/hdbscan models here if intent_predictor handles it for inference
        # but it's needed for the add_complaint endpoint's retraining flow.
        complaint_analyzer.load_models(
            classifier_path='intent_classifier.joblib',
            hdbscan_path='hdbscan_model.joblib'
        )
        print("✅ Complaint analysis models (for retraining) loaded.")

        # Load models for the new intent_predictor
        load_predictor_models(
            classifier_path='intent_classifier.joblib',
            hdbscan_path='hdbscan_model.joblib'
        )
        print("✅ Intent Predictor models loaded.")

    except Exception as e:
        print(f"❌ Failed to load artifacts or initialize LLM: {e}")
        # Depending on severity, you might want to exit or disable LLM features
        raise HTTPException(status_code=500, detail="Failed to load necessary backend components.")

# New endpoint to create a chat session
@app.post("/chatsessions", response_model=ChatSessionRead)
async def create_chat_session(*, session_create: ChatSessionCreate, session: Session = Depends(get_session)):
    db_chat_session = ChatSession.model_validate(session_create)
    session.add(db_chat_session)
    session.commit()
    session.refresh(db_chat_session)
    return db_chat_session

# New endpoint to get all chat sessions
@app.get("/chatsessions", response_model=list[ChatSessionRead])
async def get_chat_sessions(session: Session = Depends(get_session)):
    chat_sessions = session.query(ChatSession).options(selectinload(ChatSession.messages)).order_by(ChatSession.updated_at.desc()).all()
    return chat_sessions

# New endpoint to get messages for a specific session
@app.get("/chatsessions/{session_id_uuid}/messages", response_model=list[MessageRead])
async def get_messages_for_session(session_id_uuid: str, session: Session = Depends(get_session)):
    chat_session = session.query(ChatSession).filter(ChatSession.session_id_uuid == session_id_uuid).first()
    if not chat_session:
        raise HTTPException(status_code=404, detail="Chat session not found")
    messages = session.query(Message).filter(Message.session_id == chat_session.id).order_by(Message.timestamp).all()
    return messages

@app.post("/chat")
async def chat_endpoint(request: ChatRequest, session: Session = Depends(get_session)):
    try:
        user_query = request.user_query
        price = request.price
        date = request.date
        session_id_uuid = request.session_id_uuid

        db_chat_session = None
        if session_id_uuid:
            db_chat_session = session.query(ChatSession).filter(ChatSession.session_id_uuid == session_id_uuid).first()

        if not db_chat_session:
            # If session_id_uuid is not provided or not found, create a new session
            # This case ideally shouldn't happen often if frontend manages sessions correctly
            db_chat_session = ChatSession(session_id_uuid=session_id_uuid if session_id_uuid else f"chat-{datetime.now().timestamp()}", title="New Chat")
            session.add(db_chat_session)
            session.commit()
            session.refresh(db_chat_session)
            print(f"Created new chat session: {db_chat_session.session_id_uuid}")

        # 1. Save user message to database
        user_message = Message(
            session_id=db_chat_session.id,
            sender="user",
            text_content=user_query,
            price=price,
            date=date,
        )
        session.add(user_message)
        session.commit()
        session.refresh(user_message)

        # Predict intent of the issue using the new fallback mechanism
        intent_prediction_result = predict_intent_with_fallback(user_query)

        # Combine user query with validated price and date for retrieval context
        user_query_with_context = user_query
        if price:
            user_query_with_context += f" price:{price}"
        if date:
            user_query_with_context += f" date:{date}"

        # Retrieve top relevant sections
        top_sections = retrieve_sections(user_query_with_context, index, sections_data, model, k=3)

        # Process sections: use plain_summary or generate with LLM
        processed_sections = []
        for sec in top_sections:
            display_text = sec['plain_summary']
            if not display_text: # If no plain_summary, use LLM to generate one
                display_text = generate_layman_summary(sec['text'], user_query)
            
            processed_sections.append({
                "section_id": sec['section_id'],
                "chapter": sec['chapter'],
                "display_text": display_text, # This will be either plain_summary or LLM generated
                "original_text_excerpt": sec['text'][:500] + "..." if len(sec['text']) > 500 else sec['text'], # Original for reference
                "examples": sec['examples'],
                "distance": sec['distance']
            })

        # Apply rule engine
        forum_recommendation = determine_forum(price)
        eligibility_status = check_eligibility(user_query, price, date, top_sections)

        bot_response_data = {
            "query": user_query,
            "predicted_intent": intent_prediction_result["intent"],
            "intent_details": intent_prediction_result,
            "price": price,
            "date": date,
            "relevant_sections": processed_sections,
            "rule_engine_analysis": {
                "recommended_forum": forum_recommendation,
                "eligibility_status": eligibility_status
            }
        }

        # 2. Save bot response to database
        bot_message = Message(
            session_id=db_chat_session.id,
            sender="bot",
            text_content=processed_sections[0]['display_text'] if processed_sections else "No relevant sections found.", # Use summary for text_content
            response_data=json.dumps(bot_response_data) # Store full JSON response
        )
        session.add(bot_message)
        session.commit()
        session.refresh(bot_message)
        
        # Update session's updated_at timestamp and title if it's new
        db_chat_session.updated_at = datetime.now()
        if db_chat_session.title == "New Chat":
            db_chat_session.title = user_query[:50] + ("..." if len(user_query) > 50 else "")
        session.add(db_chat_session)
        session.commit()
        session.refresh(db_chat_session)

        return bot_response_data # Return the data as before for the frontend

    except Exception as e:
        session.rollback()
        raise HTTPException(status_code=500, detail=f"An error occurred during chat processing: {str(e)}")

# New endpoint for standalone complaint analysis (optional, but useful for admin)
@app.post("/analyze_complaint")
async def analyze_complaint(request: ComplaintAnalysisRequest):
    # Use the new intent predictor for analysis
    intent_prediction_result = predict_intent_with_fallback(request.complaint_text)
    
    return {"complaint_text": request.complaint_text, "predicted_intent_details": intent_prediction_result}

@app.post("/add_complaint")
async def add_complaint_data(request: AddComplaintRequest):
    if complaint_analyzer is None:
        raise HTTPException(status_code=500, detail="Complaint analyzer not initialized.")

    # Add the new complaint and label to the JSON file
    try:
        with open(complaint_analyzer.complaints_filepath, 'r+', encoding='utf-8') as f:
            data = json.load(f)
            found = False
            for intent_data in data['intents']:
                if intent_data['tag'] == request.intent_label:
                    intent_data['patterns'].append(request.complaint_text)
                    found = True
                    break
            if not found:
                # If the intent label doesn't exist, create a new one
                data['intents'].append({"tag": request.intent_label, "patterns": [request.complaint_text], "responses": [request.intent_label]})
            f.seek(0)  # Rewind to the beginning of the file
            json.dump(data, f, indent=4)
            f.truncate() # Truncate any remaining parts of the old file
        
        # Trigger retraining
        complaint_analyzer.retrain_models()

        # Reload predictor models after retraining to pick up new mappings/models
        load_predictor_models( # Reload global models in intent_predictor
            classifier_path='intent_classifier.joblib',
            hdbscan_path='hdbscan_model.joblib'
        )

        return {"status": "success", "message": "Complaint added and models retrained.", "complaint_text": request.complaint_text, "intent_label": request.intent_label}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to add complaint: {str(e)}")

if __name__ == "__main__":
    # To run the FastAPI server, use: uvicorn main:app --reload
    # The host should be 0.0.0.0 to be accessible from outside localhost for Docker/deployment
    uvicorn.run(app, host="0.0.0.0", port=8000)
